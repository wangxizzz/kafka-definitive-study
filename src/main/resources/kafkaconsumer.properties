bootstrap.servers=192.168.1.114:9092

key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

group.id=java_consumer

# consumer一次从broker获取数据的最小字节,如果broker当前没有足够多的消息满足这个条件(比如夜里活跃度小)那么broker会等待更多的消息到达在返回给consumer
# 这样既减少了consumer和broker的压力
#fetch.min.bytes

# 上面的参数指定等待多大的消息,这个参数指定等待多久返回默认500ms.如果没有足够多的消息达到需要的大小,会有500ms的延迟
#fetch.max.wait.ms

# 每个partition返回数据的总大小默认1MB 如果一个topic有20个partition和5个consumer那么每个consumer至少要4M的内存,事实上要给更多的内存给
# consumer因为有的consumer会挂 这个参数必须要比max.message.size大否则有的消息将不能被消费(consumer hang trying to read them)
# h还有一个很重要的因素是consumer处理消息的总时间,consumer必须频繁的调用poll以避免session超时和rebalance,如果一次返回的数量很多,consumer
# 就要花很长事件处理数据,也就不能继续下次poll的调用从而超时,如果发生这样的情况,这个参数就要设置的小一点,或者增加session超时时间
#max.partition.fetch.bytes

# broker认为consumer在多久没有发送心跳还认为它活着的总时间默认3s,如果超过这个时间consumer还没有heartbeats给group coordinator,就认为
# consumer挂了,group coordinator会触发rebalance,这个参数和heartbeat.interval.ms相关,heartbeat.interval.ms控制KafkaConsumer
# poll()方法多久发送一次心跳,session.timeout.ms容忍多久consumer没有发送hearbeat,一般heartbeat.interval.ms是session.timeout.ms的
# 三分之一,session.timeout.ms这个值太小的话,能更快的侦测并从失败中恢复但也会造成没必要的rebalance,
#session.timeout.ms

# 控制consumer从一个它没有提交过commit或者提交的commit失效了(比如consumer死了很久,broker上的offset记录过期了)的partition读取消息的位置
# 默认latest,也就是如果没有有效的offset那么consumer从最新的消息开始消费,earliest指如果没有有效的offset那么从头开始读取整个partition
#auto.offset.reset

# consumer是否自动提交commit offset默认true,如果想控制何时提交offset可以设置为false来最小化重复消费和避免数据丢失,如果设置为true同时也要
# 设置offset提交的频率,auto.commit.interval.ms
#enable.auto.commit

# 同一个消费者组里partition分配的策略 Range/RoundRobin
#partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor

client.id=any_string

# 一次poll()调用返回多少条数据
#max.poll.records

# socket buffer大小
#receive.buffer.bytes/send.buffer.bytes