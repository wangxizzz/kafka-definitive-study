# kafka broker 多个用,隔开
bootstrap.servers=192.168.1.102:9092

# 如何序列化ProducerRecord中的key value
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer
# 自定义序列化器
#value.serializer=com.wangxi.kafka.serializer.CustomerSerializer
#自定义分区器
#partitioner.class=com.wangxi.kafka.partition.MyPartitioner

# controls how many partition replicas must receive the record before the producer can consider the write successful
# 0 producer not wait for a reply from the broker 也就是说producer不知道消息有没有丢失, 这种模式可以达到最大的发送throughput
# 1 wait for a reply from the leader partition,如果leader失败 producer会retry,可能会造成消息丢失,如果leader挂了,但其他follower
#   还没有同步这个msg,其中一个follower被elected(via unclean leader election)就会丢失消息,这种模式下的吞吐量取决于是同步还是异步发送模式
#   同步的话会有很明显的延迟,异步的延迟取决于batch中msg的个数
# all 等待所有in-sync replicas收到消息才算success,最安全的模式,消息不会丢失,但是延迟更严重,等待所有副本的reply
acks=all

# 当消息发送失败了,producer对自动retry,除非指定retries为0 producer才不会retry,这个配置涉及到message delivery semantics
# 默认间隔100ms重试
retries=0

# 重试间隔时间,根据故障恢复的时间定 代码中不应该自己设置retry,要关心那些不可重试的异常
#retry.backoff.ms=100

# producer为每一个partition都维护了一个buffer, 这个配置的值越大会消耗更多的内存(since we will generally have one of these
# buffers for each active partition)太小会频繁的发送
batch.size=16384

# buffer会随时(只要有可用的发送线程就可以)被发送出去即使还有未使用的空间,如果想减少发送的次数可以增加这个值(微秒),这个参数建议producer在发送
# 消息时等待多长时间,以便更多的消息到达相同的batch中(fill up buffer)和TCP的Nagle算法很像 如果buffer满了会立即发送不管这个值有没有达到
# 这个参数可能会造成延迟比如buffer中的消息不多,producer会等待1微秒才发送 同一时间内到达buffer中的消息会batch在一起,如果负载很大的话,buffer
# 很快就填满了这个参数永远起不了作用,当然设置这个值在不是高负载的情况下会带来更少的高效的请求(以牺牲一点延迟为代价)
linger.ms=1

# producer buffer的总容量, 如果send的速度大于发送到broker的速度,那么这个buffer很快被用光,此时接下来的send调用会阻塞,阻塞的时间由
# max.block.ms控制 超过这个值抛出TimeoutException
buffer.memory=33554432

# 压缩算法,默认不压缩
#compression.type

# any string
client_id=melo_java

# 每个连接最大的请求个数 太大会消耗内存,设置为1能保证消息以被发送的顺序的写入broker甚至发生retr时也能保证
#max.in.flight.requests.per.connection

# 控制producer发送消息时等待reply的时间(request.timeout.ms) 获取元数据的时间 如果时间到了没有收到reply,producer要么retry要么throw
# exception
# timeout.ms 控制等待ISR的确认时间满足acks的配置,如果超时且没有足够的ack那么broker返回失败
#timeout.ms,request.timeout.ms,metadata.fetch.timeout.ms

# 控制producer调用send()和调用partitionsFor()获取元数据的阻塞时间,当buffer满了或者metadata获取不到时会阻塞 超时抛出timeout exception
#max.block.ms

# 一次请求的最大容量(1M 要和broker的message.max.bytes一起使用)
#max.request.size

# sockets使用的buffer大小 -1使用系统默认的, 当producer和consumer不在一个数据中心时可以适当增大这个大小
#receive.buffer.bytes和send.buffer.bytes

# kafka的消息顺序保证(partition是有序的) 如果要保证顺序建议设置in.flight.request.per.session=1,如果发生retry,其他msg不能被发送
